{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Boosting Techniques Assignment"
      ],
      "metadata": {
        "id": "nT6-ijM_aUUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1: What is Boosting in Machine Learning? Explain how it improves weak learners."
      ],
      "metadata": {
        "id": "-rRHB9t0aabU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":- Boosting is an ensemble learning technique that combines multiple weak learners (models that perform just slightly better than random guessing) to create a strong learner.\n",
        "\n",
        "How it improves weak learners (in short):\n",
        "\n",
        "Models are trained sequentially.\n",
        "\n",
        "Each new model focuses more on the errors made by previous models.\n",
        "\n",
        "Misclassified data points are given higher importance.\n",
        "\n",
        "Final prediction is made by combining all models (often using weighted voting)."
      ],
      "metadata": {
        "id": "E3gMJi_sar6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?"
      ],
      "metadata": {
        "id": "YJVerincauRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":- AdaBoost:\n",
        "Trains models sequentially by re-weighting misclassified data points. Each new model focuses more on samples that previous models got wrong.\n",
        "\n",
        "Gradient Boosting:\n",
        "Trains models sequentially by fitting each new model to the residual errors (gradients of the loss function) of the previous models."
      ],
      "metadata": {
        "id": "510DmLdMa11l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3: How does regularization help in XGBoost?"
      ],
      "metadata": {
        "id": "OXTJYuo6bPXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":- Adds penalties for model complexity (too many or deep trees).\n",
        "\n",
        "Controls tree depth, number of leaves, and leaf weights.\n",
        "\n",
        "Encourages simpler models that perform well on unseen data."
      ],
      "metadata": {
        "id": "1Z0pB9k6bSMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4: Why is CatBoost considered efficient for handling categorical data?"
      ],
      "metadata": {
        "id": "73hAn8-NbaVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":- CatBoost is efficient for handling categorical data because:\n",
        "\n",
        "It natively handles categorical features without manual encoding.\n",
        "\n",
        "Uses target-based (ordered) encoding, reducing target leakage.\n",
        "\n",
        "Applies ordered boosting, which improves learning stability.\n",
        "\n",
        "Avoids large one-hot encoded feature spaces."
      ],
      "metadata": {
        "id": "z5TBL3MxbbzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5: What are some real-world applications where boosting techniques are preferred over bagging methods?"
      ],
      "metadata": {
        "id": "Dp1reXOvbim5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":- Real-world applications where boosting is preferred over bagging:\n",
        "\n",
        "Fraud detection ‚Äì focuses on rare, hard-to-classify cases\n",
        "\n",
        "Credit scoring ‚Äì improves prediction on borderline customers\n",
        "\n",
        "Medical diagnosis ‚Äì emphasizes misclassified patient cases\n",
        "\n",
        "Ad click-through rate prediction ‚Äì captures complex patterns\n",
        "\n",
        "Customer churn prediction ‚Äì improves accuracy on difficult users"
      ],
      "metadata": {
        "id": "acE0nTNDbsSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6: Write a Python program to: ‚óè Train an AdaBoost Classifier on the Breast Cancer dataset ‚óè Print the model accuracy (Include your Python code and output in the code box below.)\n"
      ],
      "metadata": {
        "id": "HmLkmhfjb7hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an AdaBoost Classifier on the Breast Cancer dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training\n"
      ],
      "metadata": {
        "id": "-0EWU_MBcEOB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Write a Python program to: ‚óè Train a Gradient Boosting Regressor on the California Housing dataset ‚óè Evaluate performance using R-squared score (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "j_ChRpp5cLat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Gradient Boosting Regressor on the California Housing dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train Gradient Boosting Regressor\n",
        "model = GradientBoostingRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model using R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared Score:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqb5SH8ScFAK",
        "outputId": "d2152a7e-413d-4f3b-dba5-153ed3169ed0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared Score: 0.7756446042829697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8: Write a Python program to: ‚óè Train an XGBoost Classifier on the Breast Cancer dataset ‚óè Tune the learning rate using GridSearchCV ‚óè Print the best parameters and accuracy (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "B765VkVmce0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an XGBoost Classifier with GridSearchCV on the Breast Cancer dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define XGBoost model\n",
        "xgb_model = XGBClassifier(\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Parameter grid for learning rate\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpl-pi32cpO0",
        "outputId": "c2902034-0639-4952-98bd-71d682faa0e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:37] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [12:48:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.2}\n",
            "Model Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9: Write a Python program to: ‚óè Train a CatBoost Classifier ‚óè Plot the confusion matrix using seaborn (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "lyNK2kKdc8Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a CatBoost Classifier and plot confusion matrix\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from catboost import CatBoostClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train CatBoost Classifier\n",
        "model = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot confusion matrix using seaborn\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - CatBoost Classifier\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "jB7XY_0ldINz",
        "outputId": "e3214e3c-feec-4f90-d72d-5e8e4ac6b275"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3611057207.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior. The dataset is imbalanced, contains missing values, and has both numeric and categorical features. Describe your step-by-step data science pipeline using boosting techniques: ‚óè Data preprocessing & handling missing/categorical values ‚óè Choice between AdaBoost, XGBoost, or CatBoost ‚óè Hyperparameter tuning strategy ‚óè Evaluation metrics you'd choose and why ‚óè How the business would benefit from your model (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "uxluGTuCdUiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":- 1Ô∏è‚É£ Data Preprocessing\n",
        "\n",
        "Handling missing values\n",
        "\n",
        "Numeric features: impute using median (robust to outliers).\n",
        "\n",
        "Categorical features: fill missing values with \"Unknown\" or let CatBoost handle them natively.\n",
        "\n",
        "Handling categorical variables\n",
        "\n",
        "Prefer CatBoost because it:\n",
        "\n",
        "Natively handles categorical features\n",
        "\n",
        "Uses ordered target encoding (avoids leakage)\n",
        "\n",
        "No need for one-hot encoding ‚Üí faster & cleaner pipeline.\n",
        "\n",
        "Handling imbalance\n",
        "\n",
        "Use:\n",
        "\n",
        "class_weights\n",
        "\n",
        "or scale_pos_weight (for XGBoost)\n",
        "\n",
        "Focus on recall of defaulters.\n",
        "\n",
        "2Ô∏è‚É£ Choice of Boosting Algorithm\n",
        "\n",
        "Best choice: CatBoost\n",
        "\n",
        "Why not AdaBoost?\n",
        "\n",
        "Sensitive to noisy data\n",
        "\n",
        "Weak with missing values\n",
        "\n",
        "Why CatBoost over XGBoost?\n",
        "\n",
        "Handles categorical features automatically\n",
        "\n",
        "Performs well on imbalanced financial datasets\n",
        "\n",
        "Less preprocessing, lower leakage risk\n",
        "\n",
        "3Ô∏è‚É£ Hyperparameter Tuning Strategy\n",
        "\n",
        "Use GridSearchCV / RandomizedSearchCV\n",
        "\n",
        "Tune:\n",
        "\n",
        "learning_rate\n",
        "\n",
        "depth\n",
        "\n",
        "iterations\n",
        "\n",
        "class_weights\n",
        "\n",
        "Use Stratified K-Fold to preserve class imbalance\n",
        "\n",
        "4Ô∏è‚É£ Evaluation Metrics (Very Important for FinTech)\n",
        "\n",
        "Accuracy ‚ùå (misleading for imbalance)\n",
        "\n",
        "Use instead:\n",
        "\n",
        "Recall (Default class) ‚Üí catch risky customers\n",
        "\n",
        "Precision ‚Üí avoid rejecting good customers\n",
        "\n",
        "F1-score ‚Üí balance precision & recall\n",
        "\n",
        "ROC-AUC ‚Üí ranking quality\n",
        "\n",
        "üëâ Primary metric: Recall + ROC-AUC\n",
        "\n",
        "5Ô∏è‚É£ Business Benefits\n",
        "\n",
        "Early detection of high-risk borrowers\n",
        "\n",
        "Reduced loan defaults & financial losses\n",
        "\n",
        "Better credit decision automation\n",
        "\n",
        "Improved regulatory compliance\n",
        "\n",
        "Higher profitability & customer trust"
      ],
      "metadata": {
        "id": "WHPI_5z_dtB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loan Default Prediction using CatBoost\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Sample data loading (placeholder)\n",
        "data = pd.read_csv(\"loan_data.csv\")\n",
        "\n",
        "X = data.drop(\"default\", axis=1)\n",
        "y = data[\"default\"]\n",
        "\n",
        "# Identify categorical features\n",
        "cat_features = X.select_dtypes(include=[\"object\"]).columns\n",
        "\n",
        "# Train-test split with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# CatBoost model\n",
        "model = CatBoostClassifier(\n",
        "    loss_function=\"Logloss\",\n",
        "    eval_metric=\"AUC\",\n",
        "    auto_class_weights=\"Balanced\",\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    \"depth\": [4, 6, 8],\n",
        "    \"learning_rate\": [0.03, 0.1],\n",
        "    \"iterations\": [200, 300]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    model,\n",
        "    param_grid,\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train, cat_features=cat_features)\n",
        "\n",
        "# Best model\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "D9pW7pqydNVa",
        "outputId": "1ab6a4bb-10e3-4b12-d5cb-993e30d8a046"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3729779168.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Sample data loading (placeholder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BangoAJkdwry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}